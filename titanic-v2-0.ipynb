{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns \nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Data","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv('../input/titanic/train.csv')\ntest_data = pd.read_csv('../input/titanic/test.csv')\n\ntrain_data['train_test'] = 1\ntest_data['train_test'] = 0\ntest_data['Survived'] = np.NaN\n\ndata = pd.concat([train_data,test_data])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Exploration","metadata":{}},{"cell_type":"code","source":"train_data.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Sex:',train_data['Sex'].unique())\nprint('Pclass:',train_data['Pclass'].unique())\nprint('SibSp:',train_data['SibSp'].unique())\nprint('Parch:',train_data['Parch'].unique())\nprint('Embarked:',train_data['Embarked'].unique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.describe(include=['O'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Divide in numerical and categorical features\n\ndf_num = train_data[['Age','SibSp','Parch','Fare']]\ndf_cat = train_data[['Survived','Pclass','Sex','Ticket','Cabin','Embarked']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#distributions for all numeric variables \nfor i in df_num.columns:\n    plt.hist(df_num[i])\n    plt.title(i)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df_num.corr())\nsns.heatmap(df_num.corr())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# compare survival rate across Age, SibSp, Parch, and Fare \npd.pivot_table(train_data, index = 'Survived', values = ['Age','SibSp','Parch','Fare'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data[[\"Parch\", \"Survived\"]].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data[[\"SibSp\", \"Survived\"]].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in df_cat.columns:\n    sns.barplot(df_cat[i].value_counts().index,df_cat[i].value_counts()).set_title(i)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Comparing survival and each of these categorical variables \nprint(pd.pivot_table(train_data, index = 'Survived', columns = 'Pclass', values = 'Ticket' ,aggfunc ='count'))\nprint()\nprint(pd.pivot_table(train_data, index = 'Survived', columns = 'Sex', values = 'Ticket' ,aggfunc ='count'))\nprint()\nprint(pd.pivot_table(train_data, index = 'Survived', columns = 'Embarked', values = 'Ticket' ,aggfunc ='count'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data[[\"Pclass\", \"Survived\"]].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data[[\"Embarked\", \"Survived\"]].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"code","source":"data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop Name, Ticket and Cabin columns\n\ndata_prep = data.drop(['Name','Ticket','Cabin'], axis = 1)\ndata_prep.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Input missing data from Age and Fare with median\n\ndata_prep['Age'] = data_prep['Age'].fillna(train_data['Age'].median())\ndata_prep['Fare'] = data_prep['Fare'].fillna(train_data['Fare'].median())\ndata_prep.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop Null 'Embarked' rows (only 2)\n\ndata_prep.dropna(subset=['Embarked'],inplace = True)\ndata_prep.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get dummies from categorical features\n\ndata_prep = pd.get_dummies(data_prep, columns = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked'])\ndata_prep.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Split to train test again\n\nX_train = data_prep[data_prep['train_test'] == 1].drop(['train_test'], axis =1)\nX_test = data_prep[data_prep['train_test'] == 0].drop(['train_test'], axis =1)\ny_train = data[data['train_test'] ==1]['Survived']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Scale data from the continuous features Age and Fare to [0,1] so that they match de 'get dummies' scale from the \n# categorical features\n\nfrom sklearn.preprocessing import MinMaxScaler\nscale = MinMaxScaler()\ndata_prep_scaled = data_prep.copy()\ndata_prep_scaled[['Age','Fare']]= scale.fit_transform(data_prep_scaled[['Age','Fare']])\ndata_prep_scaled.head()\n\nX_train_scaled = data_prep_scaled[data_prep_scaled['train_test'] == 1].drop(['train_test'], axis =1)\nX_test_scaled = data_prep_scaled[data_prep_scaled['train_test'] == 0].drop(['train_test'], axis =1)\n\ny_train = data[data['train_test'] ==1]['Survived']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_prep_scaled.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_scaled.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test_scaled.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Shortlist Promising Models","metadata":{}},{"cell_type":"code","source":"# Prepare Train and Test data\n\nX_train = X_train_scaled.drop(['PassengerId','Survived'], axis=1)\nY_train = X_train_scaled[\"Survived\"]\nX_test  = X_test_scaled.drop(['PassengerId','Survived'], axis=1).copy()\nX_train.shape, Y_train.shape, X_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import models to be used\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import tree\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Possible models\n\n* Naive Bayes (40.7%)\n* Logistic Regression (80.4%)\n* Decision Tree (78.5%)\n* K Nearest Neighbor (79.1%)\n* Random Forest (79.5%)\n* Support Vector Classifier(80.3%)\n* Xtreme Gradient Boosting (81.2%)\n\n5-fold Cross Validation","metadata":{}},{"cell_type":"code","source":"# Naive Bayes\n\ngnb = GaussianNB()\ncv = cross_val_score(gnb,X_train,Y_train,cv=5)\nprint(cv)\nprint(cv.mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Logistic Regression\n\nlr = LogisticRegression(max_iter = 2000)\ncv = cross_val_score(lr,X_train,Y_train,cv=5)\nprint(cv)\nprint(cv.mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Decision Tree\n\ndt = tree.DecisionTreeClassifier(random_state = 1)\ncv = cross_val_score(dt,X_train,Y_train,cv=5)\nprint(cv)\nprint(cv.mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# K-Nearest Neighbor\n\nknn = KNeighborsClassifier()\ncv = cross_val_score(knn,X_train,Y_train,cv=5)\nprint(cv)\nprint(cv.mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Forest\n\nrf = RandomForestClassifier(random_state = 1)\ncv = cross_val_score(rf,X_train,Y_train,cv=5)\nprint(cv)\nprint(cv.mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Support Vector Classifier\n\nsvc = SVC(probability = True)\ncv = cross_val_score(svc,X_train,Y_train,cv=5)\nprint(cv)\nprint(cv.mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Xtreme Gradient Boosting\n\nfrom xgboost import XGBClassifier\nxgb = XGBClassifier(random_state =1)\ncv = cross_val_score(xgb,X_train,Y_train,cv=5)\nprint(cv)\nprint(cv.mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Fine-Tune the System\n\nChosen Model: Xtreme Gradient Boosting (Base score: 81.2%)","metadata":{}},{"cell_type":"code","source":"#Import libraries:\nimport pandas as pd\nimport numpy as np\nimport xgboost as xgb\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn import metrics   #Additional scklearn functions\nfrom sklearn.model_selection import GridSearchCV   #Perforing grid search\n\nimport matplotlib.pylab as plt\n%matplotlib inline\nfrom matplotlib.pylab import rcParams\nrcParams['figure.figsize'] = 12, 4","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define a function which will help  create XGBoost models and perform cross-validation.\n\ndef modelfit(alg, X_train, predictors, Y_train, useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n    \n    if useTrainCV:\n        xgb_param = alg.get_xgb_params()\n        xgtrain = xgb.DMatrix(X_train.values, label=Y_train.values)\n        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n            metrics='auc', early_stopping_rounds=early_stopping_rounds)\n        alg.set_params(n_estimators=cvresult.shape[0])\n    \n    #Fit the algorithm on the data\n    alg.fit(X_train, Y_train, eval_metric='auc', verbose=True)\n        \n    #Predict training set:\n    dtrain_predictions = alg.predict(X_train)\n    dtrain_predprob = alg.predict_proba(X_train)[:,1]\n        \n    #Print model report:\n    print(\"\\nModel Report\")\n    print(\"Accuracy : %.4g\" % metrics.accuracy_score(Y_train.values, dtrain_predictions))\n    print(\"AUC Score (Train): %f\" % metrics.roc_auc_score(Y_train, dtrain_predprob))\n    print(alg.n_estimators)\n    \n    # Get and plot feature importances\n    feature_important = alg.get_booster().get_score(importance_type='weight')\n    keys = list(feature_important.keys())\n    values = list(feature_important.values())\n    data = pd.DataFrame(data=values, index=keys, columns=[\"score\"]).sort_values(by = \"score\")\n    data.plot(kind='barh')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 1: Fix learning rate and number of estimators for tuning tree-based parameters","metadata":{}},{"cell_type":"code","source":"\n#Choose all predictors except 'Survived' (which is the target) & 'PassengerID'\npredictors = [x for x in X_train.columns]\n\n# Define model hyperparameters\nxgb1 = XGBClassifier(\n learning_rate =0.1, # fixed\n n_estimators=100, # fixed\n max_depth=5, # should be between 3-6 (too high values tend to overfitting; tune with CV afterwards)\n min_child_weight=1, # 1 is the default (increase to control over-fitting; tune with CV afterwards)\n gamma=0, # 0 is the default (tune afterwards)\n subsample=0.8, # Typical values: 0.5-1 (Lower values make the algorithm more conservative and prevents overfitting but too small values might lead to under-fitting)\n colsample_bytree=0.8, # same as subsample but with fraction of columns (features) instead of rows (observations)\n objective= 'binary:logistic', # logistic regression for binary classification, returns predicted probability (not class)\n scale_pos_weight=1, # 1 is the default (A value greater than 0 should be used in case of high class imbalance as it helps in faster convergence.)\n seed=10, # random number seed (Can be used for generating reproducible results and also for parameter tuning.)\n use_label_encoder=False\n) \n\n# Fit the model and generate predictions using the 'modelfit' function defined previously\nmodelfit(xgb1, X_train, predictors, Y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 2: Tune max_depth and min_child_weight","metadata":{}},{"cell_type":"code","source":"# Define parameter grid\nparam_test1 = {\n 'max_depth':range(3,10,2), # before was 5, now Grid Search on [3, 5, 7, 9]; >max_depth --> >over-fitting\n 'min_child_weight':range(1,6,2) # before was 1, now Grid Search on [1, 3, 5] ; >min_child_weight --> <over-fitting\n}\n\n# Fit model with GridSearchCV to fin optimum 'max_depth' & 'min_child_weight' values (the other values remain fixed)\ngsearch1 = GridSearchCV(\n    estimator = XGBClassifier( \n        learning_rate =0.1, \n        n_estimators=100, \n        max_depth=5,\n        min_child_weight=1, \n        gamma=0, \n        subsample=0.8, \n        colsample_bytree=0.8, \n        objective= 'binary:logistic', \n        nthread=4, \n        scale_pos_weight=1, \n        seed=10), \n    param_grid = param_test1, \n    scoring='roc_auc',   \n    cv=5)\ngsearch1.fit(X_train,Y_train)\ngsearch1.cv_results_, gsearch1.best_params_, gsearch1.best_score_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Optimum values:\n* **'max_depth'**: 9\n* **'min_child_weight'**: 3\n\nNote: 'max_depth' value of 9 is the maximum of the proposed grid, so I should check increasing this.\n\nI'll further tune both parameters with 1 above and 1 below of each one:\n* **'max_depth'**: [8, 9, 10]\n* **'min_child_weight'**: [2, 3, 4]","metadata":{}},{"cell_type":"code","source":"# Define parameter grid\nparam_test2 = {\n 'max_depth': [8, 9, 10], \n 'min_child_weight': [2, 3, 4] \n}\n\n# Fit model with GridSearchCV to fin optimum 'max_depth' & 'min_child_weight' values (the other values remain fixed)\ngsearch2 = GridSearchCV(\n    estimator = XGBClassifier( \n        learning_rate =0.1, \n        n_estimators=100, \n        max_depth=5,\n        min_child_weight=1, \n        gamma=0, \n        subsample=0.8, \n        colsample_bytree=0.8, \n        objective= 'binary:logistic', \n        nthread=4, \n        scale_pos_weight=1, \n        seed=10), \n    param_grid = param_test2, \n    scoring='roc_auc',   \n    cv=5)\ngsearch2.fit(X_train,Y_train)\ngsearch2.cv_results_, gsearch2.best_params_, gsearch2.best_score_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Optimum values:\n* **'max_depth'**: 10\n* **'min_child_weight'**: 3\n\n'max_depth' optimum value is the tested maximum, so I'll try increasing that further. I'll leave 'min_child_weight' fixed in 3 as it didn't change.","metadata":{}},{"cell_type":"code","source":"# Define parameter grid\nparam_test3 = {\n 'max_depth': [9, 10, 11, 12, 13], \n}\n\n# Fit model with GridSearchCV to fin optimum 'max_depth' & 'min_child_weight' values (the other values remain fixed)\ngsearch3 = GridSearchCV(\n    estimator = XGBClassifier( \n        learning_rate =0.1, \n        n_estimators=100, \n        max_depth=5,\n        min_child_weight=3, \n        gamma=0, \n        subsample=0.8, \n        colsample_bytree=0.8, \n        objective= 'binary:logistic', \n        nthread=4, \n        scale_pos_weight=1, \n        seed=10), \n    param_grid = param_test3, \n    scoring='roc_auc',   \n    cv=5)\ngsearch3.fit(X_train,Y_train)\ngsearch3.cv_results_, gsearch3.best_params_, gsearch3.best_score_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Optimum value:\n* **'max_depth'**: 10\n\nIt didn't change so I'll leave it fixed in 10 from now on.","metadata":{}},{"cell_type":"markdown","source":"## Step 3: Tune gamma","metadata":{}},{"cell_type":"code","source":"# Define parameter grid\nparam_test4 = {\n 'gamma':[i/10.0 for i in range(0,5)] # gamma = [0, 0.1, 0.2, 0.3, 0.4]; the default is 0; >gamma means a > minimum loss reduction requirement to make a split (makes the algoritm more conservative)\n}\n\n# Fit model with GridSearchCV to find optimum 'gamma' values (the other values remain fixed)\ngsearch4 = GridSearchCV(\n    estimator = XGBClassifier( \n        learning_rate =0.1, \n        n_estimators=100, \n        max_depth=10, # found through GridSearchCV in Step 2\n        min_child_weight=3,  # found through GridSearchCV in Step 2\n        gamma=0, \n        subsample=0.8, \n        colsample_bytree=0.8, \n        objective= 'binary:logistic', \n        nthread=4, \n        scale_pos_weight=1, \n        seed=10), \n    param_grid = param_test4, \n    scoring='roc_auc',   \n    cv=5)\ngsearch4.fit(X_train,Y_train)\ngsearch4.cv_results_, gsearch4.best_params_, gsearch4.best_score_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Optimum value:\n* **'gamma'**: 0.0\n\nThe default 'gamma' value of 0 was the optimum so I'll keep it fixed from now on.","metadata":{}},{"cell_type":"markdown","source":"Before proceeding, I'm going to re-calibrate the number of boosting rounds for the updated parameters.","metadata":{}},{"cell_type":"code","source":"#Choose all predictors except 'Survived' (which is the target) & 'PassengerID'\npredictors = [x for x in X_train.columns]\n\n# Define model hyperparameters\nxgb2 = XGBClassifier(\n learning_rate =0.1, # fixed\n n_estimators=100, # fixed\n max_depth=10,  # found through GridSearchCV in Step 2\n min_child_weight=3,  # found through GridSearchCV in Step 2\n gamma=0,  # found through GridSearchCV in Step 3\n subsample=0.8, \n colsample_bytree=0.8, \n objective= 'binary:logistic', \n scale_pos_weight=1, \n seed=10,\n use_label_encoder=False) \n\n# Fit the model and generate predictions using the 'modelfit' function defined previously\nmodelfit(xgb2, X_train, predictors, Y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Current optimization through tuning of hyperparameters:\n* Accuracy : 0.856 --> 0.8886\n* AUC Score (Train): 0.900415 --> 0.944586\n\n\nTuned hyperparameters so far:\n* 'max_depth'\n* 'min_child_weight'\n* 'gamma'","metadata":{}},{"cell_type":"markdown","source":"## Step 4: Tune subsample and colsample_bytree","metadata":{}},{"cell_type":"code","source":"# Define parameter grid\nparam_test5 = {\n 'subsample':[i/10.0 for i in range(6,10)], # [0.6, 0.7, 0.8, 0.9]\n 'colsample_bytree':[i/10.0 for i in range(6,10)] # [0.6, 0.7, 0.8, 0.9]\n}\n\n# Fit model with GridSearchCV to find optimum 'gamma' values (the other values remain fixed)\ngsearch5 = GridSearchCV(\n    estimator = XGBClassifier( \n        learning_rate =0.1, \n        n_estimators=100, \n        max_depth=10, # found through GridSearchCV in Step 2\n        min_child_weight=3,  # found through GridSearchCV in Step 2\n        gamma=0,  # found through GridSearchCV in Step 3\n        subsample=0.8, \n        colsample_bytree=0.8, \n        objective= 'binary:logistic', \n        nthread=4, \n        scale_pos_weight=1, \n        seed=10), \n    param_grid = param_test5, \n    scoring='roc_auc',   \n    cv=5)\ngsearch5.fit(X_train,Y_train)\ngsearch5.cv_results_, gsearch5.best_params_, gsearch5.best_score_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Optimum values:\n* **'colsample_bytree'**: 0.8\n* **'subsample'**: 0.9\n\nNote: 'subsample' value of 0.9 is the maximum of the proposed grid, so I should check increasing this.\n\nI'll further tune both parameters with 0.05 above and 0.05 below of each one:\n* **'colsample_bytree'**: [0.75, 0.8, 0.85]\n* **'subsample'**: [0.85, 0.9, 0.95]","metadata":{}},{"cell_type":"code","source":"# Define parameter grid\nparam_test6 = {\n 'subsample':[i/100.0 for i in range(85, 100, 5)], # [0.85, 0.90, 0.95]\n 'colsample_bytree':[i/100.0 for i in range(75, 90, 5)] # [0.75, 0.80, 0.85]\n}\n\n# Fit model with GridSearchCV to find optimum 'gamma' values (the other values remain fixed)\ngsearch6 = GridSearchCV(\n    estimator = XGBClassifier( \n        learning_rate =0.1, \n        n_estimators=100, \n        max_depth=10, # found through GridSearchCV in Step 2\n        min_child_weight=3,  # found through GridSearchCV in Step 2\n        gamma=0,  # found through GridSearchCV in Step 3\n        subsample=0.8, \n        colsample_bytree=0.8, \n        objective= 'binary:logistic', \n        nthread=4, \n        scale_pos_weight=1, \n        seed=10), \n    param_grid = param_test6, \n    scoring='roc_auc',   \n    cv=5)\ngsearch6.fit(X_train,Y_train)\ngsearch6.cv_results_, gsearch6.best_params_, gsearch6.best_score_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Optimum values:\n* **'colsample_bytree'**: 0.8\n* **'subsample'**: 0.9\n\nThey haven't changed so I'll keep both of the values fixed from now on.","metadata":{}},{"cell_type":"markdown","source":"## Step 5: Tuning Regularization Parameters","metadata":{}},{"cell_type":"code","source":"# Define parameter grid\nparam_test7 = {\n 'reg_alpha':[0, 1e-5, 1e-2, 0.1, 1, 100],\n 'reg_lambda':[1, 10, 20, 50, 100, 1000]\n}\n\n# Fit model with GridSearchCV to find optimum 'gamma' values (the other values remain fixed)\ngsearch7 = GridSearchCV(\n    estimator = XGBClassifier( \n        learning_rate =0.1, \n        n_estimators=100, \n        max_depth=10, # found through GridSearchCV in Step 2\n        min_child_weight=3,  # found through GridSearchCV in Step 2\n        gamma=0,  # found through GridSearchCV in Step 3\n        subsample=0.9,  # found through GridSearchCV in Step 4\n        colsample_bytree=0.8,  # found through GridSearchCV in Step 4 \n        objective= 'binary:logistic', \n        nthread=4, \n        scale_pos_weight=1, \n        seed=10), \n    param_grid = param_test7, \n    scoring='roc_auc',   \n    cv=5)\ngsearch7.fit(X_train,Y_train)\ngsearch7.cv_results_, gsearch7.best_params_, gsearch7.best_score_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Optimum values:\n* **'reg_alpha'**: 0\n* **'reg_lambda'**: 1\n\nThe optimum values are the defaults for both parameters so I'll leave them as that.","metadata":{}},{"cell_type":"markdown","source":"Apply changes from steps 4 and 5 to the Model:","metadata":{}},{"cell_type":"code","source":"#Choose all predictors except 'Survived' (which is the target) & 'PassengerID'\npredictors = [x for x in X_train.columns]\n\n# Define model hyperparameters\nxgb3 = XGBClassifier(\n learning_rate =0.1, # fixed\n n_estimators=100, # fixed\n max_depth=10,  # found through GridSearchCV in Step 2\n min_child_weight=3,  # found through GridSearchCV in Step 2\n gamma=0,  # found through GridSearchCV in Step 3\n subsample=0.9, # found through GridSearchCV in Step 4\n colsample_bytree=0.8, # found through GridSearchCV in Step 4\n reg_alpha=0, # found through GridSearchCV in Step 5\n reg_lambda=1,# found through GridSearchCV in Step 5\n objective= 'binary:logistic', \n scale_pos_weight=1, \n seed=10,\n use_label_encoder=False) \n\n# Fit the model and generate predictions using the 'modelfit' function defined previously\nmodelfit(xgb3, X_train, predictors, Y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"this model is slightly worse than the previous one, with the only change being the 'subsample' parameter. This parameter was 0.8 with the previous model and I found 0.9 to be the optimum value via GridSearchCV. So I don'y know why it is worse.\n\nI'll keep the previous model as it yielded better results.","metadata":{}},{"cell_type":"markdown","source":"## Step 6: Reducing Learning Rate","metadata":{}},{"cell_type":"code","source":"#Choose all predictors except 'Survived' (which is the target) & 'PassengerID'\npredictors = [x for x in X_train.columns]\n\n# Define model hyperparameters\nxgb4 = XGBClassifier(\n learning_rate =0.05, # fixed\n n_estimators=10000, # fixed\n max_depth=10,  # found through GridSearchCV in Step 2\n min_child_weight=3,  # found through GridSearchCV in Step 2\n gamma=0,  # found through GridSearchCV in Step 3\n subsample=0.8, # the optimum value found through GridSearchCV in Step 4 was 0.9 but strangely yielded a worse result in the model\n colsample_bytree=0.8, # found through GridSearchCV in Step 4\n reg_alpha=0, # found through GridSearchCV in Step 5\n reg_lambda=1,# found through GridSearchCV in Step 5\n objective= 'binary:logistic', \n scale_pos_weight=1, \n seed=10,\n use_label_encoder=False) \n\n# Fit the model and generate predictions using the 'modelfit' function defined previously\nmodelfit(xgb4, X_train, predictors, Y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This model is slightly worse than the previous one, but I'll keep this one because a lower learning rate would make a more robust model that may generalize better on the test set.","metadata":{}},{"cell_type":"markdown","source":"Generate predictions on the test set:","metadata":{}},{"cell_type":"code","source":"Y_pred = xgb4.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Generate submission file:","metadata":{}},{"cell_type":"code","source":"submission_xgb = pd.DataFrame({\n        \"PassengerId\": test_data[\"PassengerId\"],\n        \"Survived\": Y_pred\n    })\n\nsubmission_xgb.to_csv('submission_xgb.csv', index=False)\nprint(\"Your submission was successfully saved!\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}